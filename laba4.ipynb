{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AleksUv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AleksUv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'inspect' has no attribute 'getargspec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m         text_collection\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Предварительная обработка коллекции текстов\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m preprocessed_collection \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext_collection\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Создание корпуса\u001b[39;00m\n\u001b[0;32m     48\u001b[0m corpus \u001b[38;5;241m=\u001b[39m preprocessed_collection\n",
      "Cell \u001b[1;32mIn[8], line 45\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m         text_collection\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Предварительная обработка коллекции текстов\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m preprocessed_collection \u001b[38;5;241m=\u001b[39m [\u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m text_collection]\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Создание корпуса\u001b[39;00m\n\u001b[0;32m     48\u001b[0m corpus \u001b[38;5;241m=\u001b[39m preprocessed_collection\n",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     21\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [word\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39misalpha()]  \u001b[38;5;66;03m# Удаление пунктуации и чисел, приведение к нижнему регистру\u001b[39;00m\n\u001b[0;32m     22\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words]  \u001b[38;5;66;03m# Удаление стоп-слов\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m morph_analyzer \u001b[38;5;241m=\u001b[39m \u001b[43mMorphAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m lemmatized_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pymorphy2\\analyzer.py:224\u001b[0m, in \u001b[0;36mMorphAnalyzer.__init__\u001b[1;34m(self, path, lang, result_type, units, probability_estimator_cls, char_substitutes)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_type_orig \u001b[38;5;241m=\u001b[39m result_type\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_char_substitutes(char_substitutes)\n\u001b[1;32m--> 224\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43munits\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pymorphy2\\analyzer.py:235\u001b[0m, in \u001b[0;36mMorphAnalyzer._init_units\u001b[1;34m(self, units_unbound)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m item[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 235\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_units\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43munit\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_units\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_unit(item[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pymorphy2\\analyzer.py:246\u001b[0m, in \u001b[0;36mMorphAnalyzer._bound_unit\u001b[1;34m(self, unit)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_bound_unit\u001b[39m(\u001b[38;5;28mself\u001b[39m, unit):\n\u001b[1;32m--> 246\u001b[0m     unit \u001b[38;5;241m=\u001b[39m \u001b[43munit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m     unit\u001b[38;5;241m.\u001b[39minit(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m unit\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pymorphy2\\units\\base.py:35\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit.clone\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclone\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pymorphy2\\units\\base.py:76\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     74\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Return a dict with the parameters for this analyzer unit. \"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m---> 76\u001b[0m         (key, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_param_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pymorphy2\\units\\base.py:70\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[1;32m---> 70\u001b[0m args, varargs, kw, default \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetargspec\u001b[49m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(args[\u001b[38;5;241m1\u001b[39m:])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'inspect' has no attribute 'getargspec'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Загрузка стоп-слов\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "# Предварительная обработка текстов\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)  # Токенизация\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]  # Удаление пунктуации и чисел, приведение к нижнему регистру\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Удаление стоп-слов\n",
    "    morph_analyzer = MorphAnalyzer()\n",
    "    lemmatized_tokens = []\n",
    "    for word in tokens:\n",
    "        parsed_word = morph_analyzer.parse(word)[0]\n",
    "        lemma = parsed_word.normal_form\n",
    "        lemmatized_tokens.append(lemma)\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Путь к папке с файлами\n",
    "folder_path = 'C:\\Project\\Python\\sport_2021'\n",
    "\n",
    "# Получаем список файлов в папке\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Считываем тексты из файлов и выполняем предварительную обработку\n",
    "text_collection = []\n",
    "for file in files:\n",
    "    with open(os.path.join(folder_path, file), 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        text_collection.append(text)\n",
    "\n",
    "# Предварительная обработка коллекции текстов\n",
    "preprocessed_collection = [preprocess_text(text) for text in text_collection]\n",
    "\n",
    "# Создание корпуса\n",
    "corpus = preprocessed_collection\n",
    "\n",
    "# Векторизация текстов\n",
    "vectorizer = CountVectorizer(max_features=150)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Построение матрицы расстояний\n",
    "distances = squareform(pdist(X.toarray(), metric='cosine'))\n",
    "\n",
    "# Кластеризация\n",
    "spectral = SpectralClustering(affinity='precomputed', random_state=0)\n",
    "clusters = spectral.fit_predict(distances)\n",
    "\n",
    "# Визуализация кластеров\n",
    "sns.heatmap(distances, cmap='viridis')\n",
    "plt.title('Матрица расстояний')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(range(len(corpus)), clusters, c=clusters, cmap='viridis')\n",
    "plt.title('Спектральная кластеризация')\n",
    "plt.xlabel('Номер текста')\n",
    "plt.ylabel('Кластер')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
